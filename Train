# 1. Import th∆∞ vi·ªán
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import gradio as gr

from sklearn.model_selection import train_test_split
from keras.utils import to_categorical, img_to_array, load_img
from keras.models import Sequential, load_model
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from keras.callbacks import EarlyStopping

# 2. ƒê∆∞·ªùng d·∫´n t·ªõi folder ch·ª©a d·ªØ li·ªáu
data_dir = "/content/drive/MyDrive/Banknote_mau"  # ch·ªânh l·∫°i cho ƒë√∫ng
img_size = 128  # CNN kh√¥ng c·∫ßn qu√° l·ªõn, 128x128 l√† h·ª£p l√Ω

X = []
y = []

# L·∫•y danh s√°ch th∆∞ m·ª•c (m·ªói th∆∞ m·ª•c = 1 lo·∫°i ti·ªÅn: 1000_front, 1000_back, ...)
labels = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]
labels.sort()  # c·ªë ƒë·ªãnh th·ª© t·ª±
label_dict = {name: i for i, name in enumerate(labels)}

print("Danh s√°ch nh√£n:", labels)

# Ch·ªâ nh·∫≠n file ·∫£nh h·ª£p l·ªá
valid_ext = [".jpg", ".jpeg", ".png", ".bmp"]

# Load d·ªØ li·ªáu
for cls in labels:
    path = os.path.join(data_dir, cls)
    for file in os.listdir(path):
        if not any(file.lower().endswith(ext) for ext in valid_ext):
            continue
        img_path = os.path.join(path, file)
        img = cv2.imread(img_path, cv2.IMREAD_COLOR)  # d√πng ·∫£nh m√†u cho CNN
        if img is None:
            continue
        img = cv2.resize(img, (img_size, img_size))
        X.append(img)
        y.append(label_dict[cls])

X = np.array(X).astype("float32")/255.0
y = np.array(y)

print("T·ªïng s·ªë ·∫£nh load:", len(X))
print("S·ªë l·ªõp:", len(np.unique(y)))

# 3. Train/Test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# One-hot encoding
num_classes = len(labels)
y_train = to_categorical(y_train, num_classes=num_classes)
y_test  = to_categorical(y_test, num_classes=num_classes)

# 4. X√¢y CNN
model = Sequential()
model.add(Conv2D(32, (3,3), activation='relu', input_shape=(img_size, img_size, 3)))
model.add(MaxPooling2D(2,2))

model.add(Conv2D(64, (3,3), activation='relu'))
model.add(MaxPooling2D(2,2))

model.add(Conv2D(128, (3,3), activation='relu'))
model.add(MaxPooling2D(2,2))

model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes, activation='softmax'))

model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])
model.summary()

# 5. Train
early_stop = EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True)

history = model.fit(
    X_train, y_train,
    epochs=30,
    batch_size=32,
    validation_split=0.2,
    callbacks=[early_stop],
    verbose=1
)

# 6. ƒê√°nh gi√°
loss, acc = model.evaluate(X_test, y_test)
print(f"üéØ ƒê·ªô ch√≠nh x√°c test: {acc*100:.2f}%")

# 7. L∆∞u model
model.save("/content/drive/MyDrive/banknote_cnn.h5")
